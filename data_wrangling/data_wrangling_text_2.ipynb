{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process in this notebook, as well as many of the functions, were taken/adapted from Derek Jedamski's course on LinkedIn Learning found here: https://www.linkedin.com/learning/nlp-with-python-for-machine-learning-essential-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1333476068192366593</th>\n",
       "      <td>Teen pregnancy is high, HIV infection rate is growing fastest among teens, and teens are experim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364161232270487553</th>\n",
       "      <td>Even though it was a charity.  Stevens thought that speaking to DHSS rather than those suffering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364161201291153414</th>\n",
       "      <td>SCORA\\nStanding Committee on Sexual &amp;amp; Reproductive Health and Rights including HIV&amp;amp;AIDS\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364161184505737217</th>\n",
       "      <td>many females are HIV+, we wish you well, blessings, we can't heal you totally, but providing rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363439109948149760</th>\n",
       "      <td>@TheRustler83 Yep. Imagine if the government were demanding HIV tests weekly in every high school.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               full_text\n",
       "tid                                                                                                                     \n",
       "1333476068192366593  Teen pregnancy is high, HIV infection rate is growing fastest among teens, and teens are experim...\n",
       "1364161232270487553  Even though it was a charity.  Stevens thought that speaking to DHSS rather than those suffering...\n",
       "1364161201291153414  SCORA\\nStanding Committee on Sexual &amp; Reproductive Health and Rights including HIV&amp;AIDS\\...\n",
       "1364161184505737217  many females are HIV+, we wish you well, blessings, we can't heal you totally, but providing rel...\n",
       "1363439109948149760   @TheRustler83 Yep. Imagine if the government were demanding HIV tests weekly in every high school."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/compiled/full_dataset_cleaned.pkl\")\n",
    "tdf = df.loc[idx[:,],['full_text']]\n",
    "tdf = tdf.reset_index().drop(columns='uid').set_index('tid')\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_things(list_to_clean, to_remove):\n",
    "    new_list = [thing for thing in list_to_clean if thing not in to_remove]\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"code adpated from LinkedIn Learning class NLP with Python for Machine Learning Essential Training by Derek Jedamski\"\"\"\n",
    "    \n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [wn.lemmatize(word) for word in tokens if word not in stopwords]   \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_ngrams(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = \" \".join([ps.stem(word) for word in tokens if word not in stopwords])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tdf['cleaned'] = tdf['full_text'].apply(lambda x: clean_text(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer=clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(tdf['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7662, 32606)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X.toarray())\n",
    "X_df.columns = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>000</th>\n",
       "      <th>0008</th>\n",
       "      <th>001tea</th>\n",
       "      <th>008WORLD</th>\n",
       "      <th>00s</th>\n",
       "      <th>010</th>\n",
       "      <th>0121</th>\n",
       "      <th>01482</th>\n",
       "      <th>...</th>\n",
       "      <th>ãƒ‡ãƒ¥ã‚¨ãƒ</th>\n",
       "      <th>å…»çš‹ï½„</th>\n",
       "      <th>ï½ï½’</th>\n",
       "      <th>ï¾‰</th>\n",
       "      <th>ğğ”ğ„ğ„ğáµ‡áµÂº</th>\n",
       "      <th>ğ‘±ğ’ğ’Œğ’†ğ’”</th>\n",
       "      <th>ğ—¡ğ—¢ğ—ª</th>\n",
       "      <th>ğ—¥ğ—˜ğ—šğ—œğ—¦ğ—§ğ—˜ğ—¥</th>\n",
       "      <th>ğ˜½ğ™ğ™€ğ˜¼ğ™†ğ™„ğ™‰ğ™‚</th>\n",
       "      <th>ğ™Šğ™ğ˜¾</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32606 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  000  0008  001tea  008WORLD  00s  010  0121  01482  ...  ãƒ‡ãƒ¥ã‚¨ãƒ  å…»çš‹ï½„  \\\n",
       "0  0  0    0     0       0         0    0    0     0      0  ...     0    0   \n",
       "1  0  0    0     0       0         0    0    0     0      0  ...     0    0   \n",
       "2  0  0    0     0       0         0    0    0     0      0  ...     0    0   \n",
       "3  0  0    0     0       0         0    0    0     0      0  ...     0    0   \n",
       "4  0  0    0     0       0         0    0    0     0      0  ...     0    0   \n",
       "\n",
       "   ï½ï½’  ï¾‰  ğğ”ğ„ğ„ğáµ‡áµÂº  ğ‘±ğ’ğ’Œğ’†ğ’”  ğ—¡ğ—¢ğ—ª  ğ—¥ğ—˜ğ—šğ—œğ—¦ğ—§ğ—˜ğ—¥  ğ˜½ğ™ğ™€ğ˜¼ğ™†ğ™„ğ™‰ğ™‚  ğ™Šğ™ğ˜¾  \n",
       "0   0  0         0      0    0         0         0    0  \n",
       "1   0  0         0      0    0         0         0    0  \n",
       "2   0  0         0      0    0         0         0    0  \n",
       "3   0  0         0      0    0         0         0    0  \n",
       "4   0  0         0      0    0         0         0    0  \n",
       "\n",
       "[5 rows x 32606 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_vect = CountVectorizer(ngram_range=(2,2))\n",
    "X_counts = ngram_vect.fit_transform(data['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf['cleaned'] = tdf['full_text'].apply(lambda x: clean_text(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1333476068192366593</th>\n",
       "      <td>Teen pregnancy is high, HIV infection rate is growing fastest among teens, and teens are experim...</td>\n",
       "      <td>[teen, pregnancy, high, hiv, infection, rate, growing, fastest, among, teen, teen, experimenting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364161232270487553</th>\n",
       "      <td>Even though it was a charity.  Stevens thought that speaking to DHSS rather than those suffering...</td>\n",
       "      <td>[even, though, charity, stevens, thought, speaking, dhss, rather, suffering, 1980, 1990, hiv, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364161201291153414</th>\n",
       "      <td>SCORA\\nStanding Committee on Sexual &amp;amp; Reproductive Health and Rights including HIV&amp;amp;AIDS\\...</td>\n",
       "      <td>[scora, standing, committee, sexual, amp, reproductive, health, right, including, hivampaids, ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364161184505737217</th>\n",
       "      <td>many females are HIV+, we wish you well, blessings, we can't heal you totally, but providing rel...</td>\n",
       "      <td>[many, female, hiv, wish, well, blessing, cant, heal, totally, providing, relief, medicine, salv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363439109948149760</th>\n",
       "      <td>@TheRustler83 Yep. Imagine if the government were demanding HIV tests weekly in every high school.</td>\n",
       "      <td>[therustler83, yep, imagine, government, demanding, hiv, test, weekly, every, high, school]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               full_text  \\\n",
       "tid                                                                                                                        \n",
       "1333476068192366593  Teen pregnancy is high, HIV infection rate is growing fastest among teens, and teens are experim...   \n",
       "1364161232270487553  Even though it was a charity.  Stevens thought that speaking to DHSS rather than those suffering...   \n",
       "1364161201291153414  SCORA\\nStanding Committee on Sexual &amp; Reproductive Health and Rights including HIV&amp;AIDS\\...   \n",
       "1364161184505737217  many females are HIV+, we wish you well, blessings, we can't heal you totally, but providing rel...   \n",
       "1363439109948149760   @TheRustler83 Yep. Imagine if the government were demanding HIV tests weekly in every high school.   \n",
       "\n",
       "                                                                                                                 cleaned  \n",
       "tid                                                                                                                       \n",
       "1333476068192366593  [teen, pregnancy, high, hiv, infection, rate, growing, fastest, among, teen, teen, experimenting...  \n",
       "1364161232270487553  [even, though, charity, stevens, thought, speaking, dhss, rather, suffering, 1980, 1990, hiv, ha...  \n",
       "1364161201291153414  [scora, standing, committee, sexual, amp, reproductive, health, right, including, hivampaids, ci...  \n",
       "1364161184505737217  [many, female, hiv, wish, well, blessing, cant, heal, totally, providing, relief, medicine, salv...  \n",
       "1363439109948149760          [therustler83, yep, imagine, government, demanding, hiv, test, weekly, every, high, school]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(tdf['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>000</th>\n",
       "      <th>0008</th>\n",
       "      <th>001tea</th>\n",
       "      <th>008WORLD</th>\n",
       "      <th>00s</th>\n",
       "      <th>010</th>\n",
       "      <th>0121</th>\n",
       "      <th>01482</th>\n",
       "      <th>...</th>\n",
       "      <th>ãƒ‡ãƒ¥ã‚¨ãƒ</th>\n",
       "      <th>å…»çš‹ï½„</th>\n",
       "      <th>ï½ï½’</th>\n",
       "      <th>ï¾‰</th>\n",
       "      <th>ğğ”ğ„ğ„ğáµ‡áµÂº</th>\n",
       "      <th>ğ‘±ğ’ğ’Œğ’†ğ’”</th>\n",
       "      <th>ğ—¡ğ—¢ğ—ª</th>\n",
       "      <th>ğ—¥ğ—˜ğ—šğ—œğ—¦ğ—§ğ—˜ğ—¥</th>\n",
       "      <th>ğ˜½ğ™ğ™€ğ˜¼ğ™†ğ™„ğ™‰ğ™‚</th>\n",
       "      <th>ğ™Šğ™ğ˜¾</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32606 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0  000  0008  001tea  008WORLD  00s  010  0121  01482  ...  ãƒ‡ãƒ¥ã‚¨ãƒ  \\\n",
       "0  0.0  0.0  0.0   0.0     0.0       0.0  0.0  0.0   0.0    0.0  ...   0.0   \n",
       "1  0.0  0.0  0.0   0.0     0.0       0.0  0.0  0.0   0.0    0.0  ...   0.0   \n",
       "2  0.0  0.0  0.0   0.0     0.0       0.0  0.0  0.0   0.0    0.0  ...   0.0   \n",
       "3  0.0  0.0  0.0   0.0     0.0       0.0  0.0  0.0   0.0    0.0  ...   0.0   \n",
       "4  0.0  0.0  0.0   0.0     0.0       0.0  0.0  0.0   0.0    0.0  ...   0.0   \n",
       "\n",
       "   å…»çš‹ï½„   ï½ï½’    ï¾‰  ğğ”ğ„ğ„ğáµ‡áµÂº  ğ‘±ğ’ğ’Œğ’†ğ’”  ğ—¡ğ—¢ğ—ª  ğ—¥ğ—˜ğ—šğ—œğ—¦ğ—§ğ—˜ğ—¥  ğ˜½ğ™ğ™€ğ˜¼ğ™†ğ™„ğ™‰ğ™‚  ğ™Šğ™ğ˜¾  \n",
       "0  0.0  0.0  0.0       0.0    0.0  0.0       0.0       0.0  0.0  \n",
       "1  0.0  0.0  0.0       0.0    0.0  0.0       0.0       0.0  0.0  \n",
       "2  0.0  0.0  0.0       0.0    0.0  0.0       0.0       0.0  0.0  \n",
       "3  0.0  0.0  0.0       0.0    0.0  0.0       0.0       0.0  0.0  \n",
       "4  0.0  0.0  0.0       0.0    0.0  0.0       0.0       0.0  0.0  \n",
       "\n",
       "[5 rows x 32606 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n",
    "X_tfidf_df.columns = tfidf_vect.get_feature_names()\n",
    "X_tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
