{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(os.path.join(os.path.dirname(sys.path[0]), 'scripts'))\n",
    "import scripts.data_acquisition_tools as dat\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\smana\\\\Documents\\\\Springboard\\\\Capstone_Two\\\\data_wrangling', 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\python38.zip', 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\DLLs', 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib', 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp', '', 'C:\\\\Users\\\\smana\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages', 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages', 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\smana\\\\.ipython', 'C:\\\\Users\\\\smana\\\\Documents\\\\Springboard\\\\Capstone_Two']\n"
     ]
    }
   ],
   "source": [
    "dat.test_sys_things()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(sys.path[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.dirname(sys.path[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter_api_access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\smana\\\\Documents\\\\Springboard\\\\Capstone_Two\\\\data_wrangling',\n",
       " 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\python38.zip',\n",
       " 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\DLLs',\n",
       " 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib',\n",
       " 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp',\n",
       " '',\n",
       " 'C:\\\\Users\\\\smana\\\\AppData\\\\Roaming\\\\Python\\\\Python38\\\\site-packages',\n",
       " 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\smana\\\\anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\smana\\\\.ipython',\n",
       " 'C:\\\\Users\\\\smana\\\\Documents\\\\Springboard\\\\Capstone_Two']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\smana\\\\Documents\\\\Springboard\\\\Capstone Two'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-4a394ac58c20>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-4a394ac58c20>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    import .scripts.data_acquisition_tools as dat\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import .scripts.data_acquisition_tools as dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_acquisition_tools as dat\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "save_loc = os.path.join(data.__path__[0],r\"raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load hashtags from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = pd.read_pickle(os.path.join(data.__path__[0], r'compiled\\common_hashtags.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aids',\n",
       " 'disclose',\n",
       " 'endaids',\n",
       " 'endhivepidemic',\n",
       " 'endhivstigma',\n",
       " 'hiv',\n",
       " 'hivhometest',\n",
       " 'hivstigma',\n",
       " 'hivtestweek',\n",
       " 'hivtreatment',\n",
       " 'plhiv',\n",
       " 'plwhiv',\n",
       " 'prep',\n",
       " 'sciencenotstigma',\n",
       " 'uequalsu',\n",
       " 'vaccinatethemostvulnerable',\n",
       " 'vaccinatethemostvulneranle'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#had to remove #disclose due to the recent DISCLOSE act from US congress\n",
    "#removed the last one as I didn't realize initially it's a typo\n",
    "hashtags.remove('disclose')\n",
    "hashtags.remove('vaccinatethemostvulneranle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "(uequalsu OR hivstigma OR #aids OR hivtreatment OR #prep OR hivhometest OR endaids OR sciencenotstigma OR endhivstigma OR plhiv OR hivtestweek OR plwhiv OR vaccinatethemostvulnerable OR hiv OR endhivepidemic) -covid lang:en\n"
     ]
    }
   ],
   "source": [
    "#format the hashtags to add operators and hash symbol where necessary, as well as language filter\n",
    "#need to remove keyword covid because otherwise it dominates the results\n",
    "add_hash = [\"#{}\".format(h) if (h=='aids') or (h=='prep') else h for h in hashtags]\n",
    "add_or = \" OR \".join(add_hash)\n",
    "query = \"({}) -covid lang:en\".format(add_or)\n",
    "print(len(query))\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do a test search on the standard api (with generous rate limits) to make sure everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(save_loc, 'test_search.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dat.api_search(query, fname, n_items=500, return_dict=True)\n",
    "del test['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri Mar 05 19:19:19 +0000 2021'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri Mar 05 17:50:54 +0000 2021'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[499]['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('en', 500)]\n"
     ]
    }
   ],
   "source": [
    "langs = []\n",
    "for key in test.keys():\n",
    "    langs.append(test[key]['lang'])\n",
    "\n",
    "from collections import Counter\n",
    "lang_counts = Counter(langs)\n",
    "print(lang_counts.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had some trouble in previous pulls with the lang command in the query not working properly, but this seems to have worked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pull tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to account for the way topics cluster on twitter (due to intra-community discussion of the same topic over a short period of time), as well as potential time zone biases, every 5000 tweets (10 pulls), I set the timestamp to go back 2 days and randomize start time by subtracting a random number of hours (up to 23)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2021, 2, 25, 23, 24, 41, tzinfo=datetime.timezone.utc),\n",
       " '202102252324',\n",
       " 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set parameters to begin collecting tweets that are at least 1 week old\n",
    "random.seed(42)\n",
    "h = random.randint(0,23)\n",
    "last_dt, last_str = dat.timestamp_to_toDate((datetime.now(timezone.utc) - timedelta(days=7, hours=h)).strftime(\"%a %b %d %H:%M:%S %z %Y\"))\n",
    "\n",
    "n = 1\n",
    "saved_params = (last_dt, last_str, n)\n",
    "saved_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-25 16:54:28+00:00 n=7\n",
      "2021-02-25 15:44:03+00:00 n=8\n",
      "2021-02-25 14:39:34+00:00 n=9\n",
      "going back 2 days\n",
      "2021-02-23 10:34:01+00:00 n=10\n",
      "2021-02-23 08:54:53+00:00 n=11\n",
      "2021-02-23 06:55:06+00:00 n=12\n",
      "2021-02-23 04:11:17+00:00 n=13\n",
      "(datetime.datetime(2021, 2, 23, 4, 11, 17, tzinfo=datetime.timezone.utc), '202102230411', 13)\n",
      "exception =  {'message': 'Exceeded rate limit', 'sent': '2021-03-05T19:27:12+00:00', 'transactionId': '0053f62600350551'}\n",
      "...sleeping...\n",
      "2021-02-23 04:11:17+00:00 n=13\n",
      "2021-02-23 01:39:17+00:00 n=14\n",
      "2021-02-22 23:20:45+00:00 n=15\n",
      "2021-02-22 21:48:41+00:00 n=16\n",
      "2021-02-22 20:22:22+00:00 n=17\n",
      "2021-02-22 19:12:16+00:00 n=18\n",
      "2021-02-22 18:05:57+00:00 n=19\n",
      "(datetime.datetime(2021, 2, 22, 18, 5, 57, tzinfo=datetime.timezone.utc), '202102221805', 19)\n",
      "exception =  {'message': 'Exceeded rate limit', 'sent': '2021-03-05T19:28:32+00:00', 'transactionId': '005668d500996756'}\n",
      "...sleeping...\n",
      "2021-02-22 18:05:57+00:00 n=19\n",
      "going back 2 days\n",
      "2021-02-20 17:06:29+00:00 n=20\n",
      "2021-02-20 15:52:17+00:00 n=21\n",
      "2021-02-20 14:55:22+00:00 n=22\n",
      "2021-02-20 13:39:38+00:00 n=23\n",
      "2021-02-20 12:28:09+00:00 n=24\n",
      "2021-02-20 11:30:22+00:00 n=25\n",
      "(datetime.datetime(2021, 2, 20, 11, 30, 22, tzinfo=datetime.timezone.utc), '202102201130', 25)\n",
      "exception =  {'message': 'Exceeded rate limit', 'sent': '2021-03-05T19:29:53+00:00', 'transactionId': '00f1e81c00b40404'}\n",
      "...sleeping...\n",
      "2021-02-20 11:30:22+00:00 n=25\n",
      "2021-02-20 10:20:14+00:00 n=26\n",
      "2021-02-20 08:57:34+00:00 n=27\n",
      "2021-02-20 07:33:18+00:00 n=28\n",
      "2021-02-20 05:48:06+00:00 n=29\n",
      "going back 2 days\n",
      "2021-02-17 04:43:07+00:00 n=30\n",
      "2021-02-17 02:34:25+00:00 n=31\n",
      "(datetime.datetime(2021, 2, 17, 2, 34, 25, tzinfo=datetime.timezone.utc), '202102170234', 31)\n",
      "exception =  {'message': 'Exceeded rate limit', 'sent': '2021-03-05T19:31:16+00:00', 'transactionId': '00b822ce005c1c57'}\n",
      "...sleeping...\n",
      "2021-02-17 02:34:25+00:00 n=31\n",
      "2021-02-17 00:10:04+00:00 n=32\n",
      "2021-02-16 22:21:18+00:00 n=33\n",
      "2021-02-16 20:56:31+00:00 n=34\n",
      "2021-02-16 19:39:52+00:00 n=35\n",
      "2021-02-16 18:31:15+00:00 n=36\n",
      "2021-02-16 17:21:37+00:00 n=37\n",
      "(datetime.datetime(2021, 2, 16, 17, 21, 37, tzinfo=datetime.timezone.utc), '202102161721', 37)\n",
      "exception =  {'message': 'Exceeded rate limit', 'sent': '2021-03-05T19:32:41+00:00', 'transactionId': '00ef2e9f000a35d2'}\n",
      "...sleeping...\n",
      "2021-02-16 17:21:37+00:00 n=37\n",
      "2021-02-16 16:10:11+00:00 n=38\n",
      "2021-02-16 15:05:41+00:00 n=39\n",
      "going back 2 days\n",
      "2021-02-14 06:04:09+00:00 n=40\n"
     ]
    }
   ],
   "source": [
    "#collect 20,000 tweets\n",
    "last_dt, last_str = saved_params[:2]\n",
    "\n",
    "n = saved_params[2]\n",
    "while n <= 40:\n",
    "    if n % 10 == 0:\n",
    "        h = random.randint(0,23)\n",
    "        last_dt, last_str = dat.timestamp_to_toDate((last_dt - timedelta(days=2, hours=h)).strftime(\"%a %b %d %H:%M:%S %z %Y\"))\n",
    "        print(\"going back 2 days\")\n",
    "    try:\n",
    "        print(last_dt, \"n={}\".format(n))\n",
    "        fname = os.path.join(save_loc, 'main_search{}.json'.format(n))\n",
    "        search = dat.api_advanced_search(query, fname, which_api='30day', todate=last_str, n_items=500, return_dict=True)\n",
    "        last_dt, last_str = dat.timestamp_to_toDate(search[499]['created_at'])    \n",
    "        n += 1\n",
    "    except Exception as e:\n",
    "        saved_params = last_dt, last_str, n\n",
    "        print(saved_params)\n",
    "        print(\"exception = \", e)\n",
    "        print(\"...sleeping...\")\n",
    "        time.sleep(60)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
