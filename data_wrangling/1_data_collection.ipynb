{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import the things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(r\"..\\path.txt\") as p:\n",
    "    path = p.readlines()[0]\n",
    "import sys\n",
    "sys.path.append(path)\n",
    "\n",
    "import data_acquisition_tools as dat\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load hashtags from previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = pd.read_pickle( r'..\\data_files\\common_hashtags.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aids',\n",
       " 'disclose',\n",
       " 'endaids',\n",
       " 'endhivepidemic',\n",
       " 'endhivstigma',\n",
       " 'hiv',\n",
       " 'hivhometest',\n",
       " 'hivstigma',\n",
       " 'hivtestweek',\n",
       " 'hivtreatment',\n",
       " 'plhiv',\n",
       " 'plwhiv',\n",
       " 'prep',\n",
       " 'sciencenotstigma',\n",
       " 'uequalsu',\n",
       " 'vaccinatethemostvulnerable',\n",
       " 'vaccinatethemostvulneranle'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#had to remove #disclose due to the recent DISCLOSE act from US congress\n",
    "#removed the last one as I didn't realize initially it's a typo\n",
    "hashtags.remove('disclose')\n",
    "hashtags.remove('vaccinatethemostvulneranle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n",
      "(endaids OR hivstigma OR sciencenotstigma OR vaccinatethemostvulnerable OR plwhiv OR endhivepidemic OR hivtestweek OR #aids OR hiv OR uequalsu OR hivhometest OR hivtreatment OR endhivstigma OR #prep OR plhiv) -covid lang:en\n"
     ]
    }
   ],
   "source": [
    "#format the hashtags to add operators and hash symbol where necessary, as well as language filter\n",
    "#need to remove keyword covid because otherwise it dominates the results\n",
    "add_hash = [\"#{}\".format(h) if (h=='aids') or (h=='prep') else h for h in hashtags]\n",
    "add_or = \" OR \".join(add_hash)\n",
    "query = \"({}) -covid lang:en\".format(add_or)\n",
    "print(len(query))\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "(endaids OR hivstigma OR #aids OR hiv OR uequalsu OR hivtreatment OR endhivstigma OR #prep OR plhiv) -covid lang:en\n"
     ]
    }
   ],
   "source": [
    "#need a shorter query for the full archive API\n",
    "query2 = '(endaids OR hivstigma OR #aids OR hiv OR uequalsu OR hivtreatment OR endhivstigma OR #prep OR plhiv) -covid lang:en'\n",
    "print(len(query2))\n",
    "print(query2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### do a test search on the standard api (with generous rate limits) to make sure everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = r'..\\data_files\\test_file.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test = dat.api_search(query, fname, n_items=500, return_dict=True)\n",
    "del test['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tue Apr 06 02:43:02 +0000 2021'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tue Apr 06 01:50:37 +0000 2021'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[499]['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @DrMikeStanton: HIV vaccine might be right around the corner.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[499]['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('en', 500)]\n"
     ]
    }
   ],
   "source": [
    "langs = []\n",
    "for key in test.keys():\n",
    "    langs.append(test[key]['lang'])\n",
    "\n",
    "from collections import Counter\n",
    "lang_counts = Counter(langs)\n",
    "print(lang_counts.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had some trouble in previous pulls with the lang command in the query not working properly, but this seems to have worked. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pull tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to account for the way topics cluster on twitter (due to intra-community discussion of the same topic over a short period of time), as well as potential time zone biases, every 2500 tweets (5 pulls), I set the timestamp to go back 2 days and randomize start time by subtracting a random number of hours (up to 23)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2021, 3, 29, 6, 43, 47, tzinfo=datetime.timezone.utc),\n",
       " '202103290643',\n",
       " 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set parameters to begin collecting tweets that are at least 1 week old\n",
    "random.seed(42)\n",
    "h = random.randint(0,23)\n",
    "last_dt, last_str = dat.timestamp_to_toDate((datetime.now(timezone.utc) - timedelta(days=7, hours=h)).strftime(\"%a %b %d %H:%M:%S %z %Y\"))\n",
    "\n",
    "n = 1\n",
    "saved_params = (last_dt, last_str, n)\n",
    "saved_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect 20,000 tweets\n",
    "last_dt, last_str = saved_params[:2]\n",
    "\n",
    "n = saved_params[2]\n",
    "while n <= 40:\n",
    "    if n % 5 == 0:\n",
    "        h = random.randint(0,23)\n",
    "        last_dt, last_str = dat.timestamp_to_toDate((last_dt - timedelta(days=2, hours=h)).strftime(\"%a %b %d %H:%M:%S %z %Y\"))\n",
    "        print(\"going back 2 days\")\n",
    "    try:\n",
    "        print(last_dt, \"n={}\".format(n))\n",
    "        fname = os.path.join(r'..\\data_files', 'main_search{}.json'.format(n))\n",
    "        search = dat.api_advanced_search(query, fname, which_api='30day', todate=last_str, n_items=500, return_dict=True)\n",
    "        last_dt, last_str = dat.timestamp_to_toDate(search[499]['created_at'])    \n",
    "        n += 1\n",
    "    except Exception as e:\n",
    "        saved_params = last_dt, last_str, n\n",
    "        print(saved_params)\n",
    "        print(\"exception = \", e)\n",
    "        print(\"...sleeping...\")\n",
    "        time.sleep(60)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2021, 3, 6, 6, 11, 56, tzinfo=datetime.timezone.utc),\n",
       " '202103060611',\n",
       " 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set parameters to begin collecting tweets that are at least 1 week old\n",
    "random.seed(42)\n",
    "h = random.randint(0,23)\n",
    "last_dt, last_str = dat.timestamp_to_toDate((datetime.now(timezone.utc) - timedelta(days=31, hours=h)).strftime(\"%a %b %d %H:%M:%S %z %Y\"))\n",
    "\n",
    "n = 1\n",
    "saved_params = (last_dt, last_str, n)\n",
    "saved_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going back 5 days\n",
      "2021-02-24 03:11:56+00:00 n=1\n",
      "(datetime.datetime(2021, 2, 24, 3, 11, 56, tzinfo=datetime.timezone.utc), '202102240311', 1)\n",
      "exception =  Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/tweets/search/fullarchive/fullarchive2.json?toDate=202102240311&query=%28endaids+OR+hivstigma+OR+%23aids+OR+hiv+OR+uequalsu+OR+hivtreatment+OR+endhivstigma+OR+%23prep+OR+plhiv%29+-covid+lang%3Aen (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002161EF49400>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "...sleeping...\n",
      "going back 5 days\n",
      "2021-02-18 04:11:56+00:00 n=1\n",
      "going back 5 days\n",
      "2021-02-12 18:20:19+00:00 n=2\n",
      "going back 5 days\n",
      "2021-02-07 10:13:51+00:00 n=3\n",
      "going back 5 days\n",
      "2021-02-02 01:19:33+00:00 n=4\n",
      "going back 5 days\n",
      "2021-01-27 19:35:56+00:00 n=5\n",
      "going back 5 days\n",
      "2021-01-21 19:29:08+00:00 n=6\n",
      "going back 5 days\n",
      "2021-01-16 15:23:16+00:00 n=7\n",
      "(datetime.datetime(2021, 1, 16, 15, 23, 16, tzinfo=datetime.timezone.utc), '202101161523', 7)\n",
      "exception =  {'message': 'Exceeded rate limit', 'sent': '2021-04-07T02:20:35+00:00', 'transactionId': '00e78c14007a26b2'}\n",
      "...sleeping...\n",
      "going back 5 days\n",
      "2021-01-10 18:23:16+00:00 n=7\n",
      "going back 5 days\n",
      "2021-01-04 17:24:05+00:00 n=8\n",
      "going back 5 days\n",
      "2020-12-29 22:36:43+00:00 n=9\n",
      "going back 5 days\n",
      "2020-12-24 19:44:37+00:00 n=10\n"
     ]
    }
   ],
   "source": [
    "#collect 5,000 tweets using the full archive API\n",
    "#start 1 month ago, go back 5 days between every pull\n",
    "last_dt, last_str = saved_params[:2]\n",
    "\n",
    "n = saved_params[2]\n",
    "while n <= 10:\n",
    "    h = random.randint(0,23)\n",
    "    last_dt, last_str = dat.timestamp_to_toDate((last_dt - timedelta(days=5, hours=h)).strftime(\"%a %b %d %H:%M:%S %z %Y\"))\n",
    "    print(\"going back 5 days\")\n",
    "    try:\n",
    "        print(last_dt, \"n={}\".format(n))\n",
    "        fname = os.path.join(r'..\\data_files', 'main_search{}.json'.format(n))\n",
    "        search = dat.api_advanced_search(query2, fname, which_api='full', todate=last_str, n_items=500, return_dict=True)\n",
    "        last_dt, last_str = dat.timestamp_to_toDate(search[499]['created_at'])    \n",
    "        n += 1\n",
    "    except Exception as e:\n",
    "        saved_params = last_dt, last_str, n\n",
    "        print(saved_params)\n",
    "        print(\"exception = \", e)\n",
    "        print(\"...sleeping...\")\n",
    "        time.sleep(60)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
